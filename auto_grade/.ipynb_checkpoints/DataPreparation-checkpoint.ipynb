{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51702e35-cc46-4af6-ae72-f473f2ab4580",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:80% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import all necessary libraries\n",
    "import re\n",
    "import pprint\n",
    "\n",
    "import hashlib\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:80% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0892ece4-18e0-499b-bcf2-eda65348ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions to extract results from data, as well as output data\n",
    "\n",
    "def extract_score(s):\n",
    "    \"\"\"Extract score from dictionary.\"\"\"\n",
    "    assert len(s) <= 1\n",
    "    if 'scale_1' in s:\n",
    "        return int(s['scale_1'])\n",
    "    elif 'scale_2' in s:\n",
    "        return int(s['scale_2'])\n",
    "    elif 'scale_3' in s:\n",
    "        return int(s['scale_3'])\n",
    "    elif 'scale_4' in s:\n",
    "        return int(s['scale_4'])\n",
    "    elif 'scale_5' in s:\n",
    "        return int(s['scale_5'])\n",
    "    \n",
    "    return np.nan\n",
    "\n",
    "def load_results(filename, name, verbose=False):\n",
    "    \"\"\"Load results.\"\"\"\n",
    "    data = {}\n",
    "    \n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            v = json.loads(line)\n",
    "\n",
    "            if len(v['id']) > len('2000000'):\n",
    "                if verbose:\n",
    "                    print(v)\n",
    "                continue\n",
    "\n",
    "            h = hashlib.md5(v['displayed_text'].encode('utf-8')).hexdigest()\n",
    "            data[v['id']] = {\n",
    "                'id': v['id'],\n",
    "                'displayed_text': ' '.join(v['displayed_text'][:].split()),\n",
    "                #'span_annotations': v['span_annotations'],\n",
    "                #'behavioral_data': v['behavioral_data'],\n",
    "\n",
    "                'calculation_error': 1 if 'Calculation Error' in v['label_annotations'].get('Problems', '') else 0,\n",
    "                'hallucination_error': 1 if 'Hallucinations' in v['label_annotations'].get('Problems', '') else 0,\n",
    "                'omission_error': 1 if 'Omission' in v['label_annotations'].get('Problems', '') else 0,\n",
    "                'irrelevant_error': 1 if 'Irrelevant' in v['label_annotations'].get('Problems', '') else 0,\n",
    "                'logic_error': 1 if 'Logic Error' in v['label_annotations'].get('Problems', '') else 0,\n",
    "                'everything_okay': 1 if 'Everything is ok.' in v['label_annotations'].get('Problems', '') else 0,\n",
    "\n",
    "                'correctness_score': extract_score(v['label_annotations'].get('conclusion_Score', {})),\n",
    "                'logic_score': extract_score(v['label_annotations'].get('logic_Score', {})),\n",
    "                'truthfulness_score': extract_score(v['label_annotations'].get('truthfulness_Score', {})),\n",
    "\n",
    "                'confidence_score': extract_score(v['label_annotations'].get('Confidence_Score', {})),\n",
    "\n",
    "                'info': v['label_annotations'].get('textbox_input', {}).get('Descriptive grade', '') + \\\n",
    "                        ', ' + v['label_annotations'].get('textbox_input', {}).get('Comments', ''),\n",
    "                'difficulty': int(v['id'][0]),  # 1=easy, 2=medium, 3=hard\n",
    "                'originality': int(v['id'][1]),  # 0=copied, 1=paraphrased, 2=original\n",
    "                'context': int(v['id'][2]),  # 0=no, 1=relevant, 2=vague, 3.irrelevant\n",
    "                'author': int(v['id'][3]),  # 0=no, 1=relevant, 2=vague, 3.irrelevant\n",
    "                'question_id': v['id'][-4:],\n",
    "            }\n",
    "    \n",
    "    data = pd.DataFrame(data).T.set_index('id').sort_values(['question_id', 'context'])\n",
    "    data['grader'] = name\n",
    "    \n",
    "    return data\n",
    "\n",
    "def output_data(df_out, filename):\n",
    "    # Convert DataFrame to JSON string\n",
    "    json_str = df_out.to_json(orient=\"records\")\n",
    "    \n",
    "    # Wrap the JSON string in {}\n",
    "    json_str_wrapped = f'{{\"data\": {json_str}}}'\n",
    "    \n",
    "    # Write the JSON string to a file\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(json_str_wrapped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c85c8dd6-83f7-4ac1-a43c-9c820a8620ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data\n",
    "df = pd.concat([\n",
    "    load_results('raw_data/abram.jsonl', name='abram'),\n",
    "    load_results('raw_data/haoran.jsonl', name='haoran'),\n",
    "    load_results('raw_data/louis.jsonl', name='louis'),\n",
    "    load_results('raw_data/mikelixiang.jsonl', name='mikeli'),\n",
    "    load_results('raw_data/Ryan_{{HYr}}.jsonl', name='ryan'),\n",
    "    load_results('raw_data/ziwei.jsonl', name='ziwei'),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a26d2cc-85da-4c9e-9d2d-7640bbb23383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train and test data have been exported to 'train_data.json' and 'test_data.json'\n"
     ]
    }
   ],
   "source": [
    "# perform train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the grouping columns\n",
    "group_cols = ['difficulty', 'originality', 'author', 'question_id']\n",
    "\n",
    "# Group the DataFrame by the specified columns and get unique groups\n",
    "groups = df.groupby(group_cols).apply(lambda x: x.index.tolist()).tolist()\n",
    "\n",
    "# Perform train-test split on the groups\n",
    "train_groups, test_groups = train_test_split(groups, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten the lists of groups into lists of indices\n",
    "train_indices = [idx for group in train_groups for idx in group]\n",
    "test_indices = [idx for group in test_groups for idx in group]\n",
    "\n",
    "# Filter the original DataFrame based on train and test indices\n",
    "train_df = df.loc[train_indices].drop_duplicates()\n",
    "test_df = df.loc[test_indices].drop_duplicates()\n",
    "\n",
    "# Save the train and test DataFrames to JSON files\n",
    "output_data(train_df,\"train_data.json\")\n",
    "output_data(test_df,\"test_data.json\")\n",
    "\n",
    "print(\"Train and test data have been exported to 'train_data.json' and 'test_data.json'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575e4b9f-b1e4-43fd-b82a-b9ae58d5ed08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbde3777-0d67-4c05-8c20-0bf2752a1713",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
